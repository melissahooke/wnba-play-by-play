{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from pytz import timezone\n",
    "import espn_scraper as espn #https://github.com/andr3w321/espn_scraper\n",
    "import json\n",
    "\n",
    "def strzero(num):\n",
    "    num = str(num)\n",
    "    if len(num) == 1:\n",
    "        num = '0'+num\n",
    "    return(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "month = 9\n",
    "day = 12\n",
    "date = '20190822'\n",
    "schedURL = 'https://www.espn.com/wnba/scoreboard/_/date/'+str(year)+strzero(month)+strzero(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = []\n",
    "game_info = []\n",
    "years = list(range(1997,2022))\n",
    "years = [year]\n",
    "years.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all of the game ids ever\n",
    "for year in years:\n",
    "    prev_len = len(game_ids)\n",
    "    scoreboard_urls= espn.get_all_scoreboard_urls('wnba', year) \n",
    "    for scoreboard_url in scoreboard_urls:\n",
    "        data = espn.get_url(scoreboard_url, cached_path=\"cached_data\")\n",
    "        try:\n",
    "            for event in data['content']:  \n",
    "                if event['analytics']['gameId'] not in game_ids:\n",
    "                    game_ids.append(event['analytics']['gameId'])\n",
    "                    game_info.append([event['analytics']['gameId'],year])\n",
    "        except:\n",
    "            pass\n",
    "    print([year,len(game_ids)-prev_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id_df = pd.DataFrame(game_info)\n",
    "game_id_df.columns = ['GameID','year']\n",
    "game_id_df.to_csv('game_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(game_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game_ids_csv = pd.read_csv('not-scraped.csv')\n",
    "GameID = '401105109'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_game_data(GameID):\n",
    "if True:\n",
    "    GameID = str(GameID)\n",
    "\n",
    "    #scrape html\n",
    "    URL = 'https://www.espn.com/wnba/playbyplay/_/gameId/'+GameID\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #extract json including pbp data\n",
    "    #from: https://stackoverflow.com/questions/13323976/how-to-extract-a-json-object-that-was-defined-in-a-html-page-javascript-block-us\n",
    "    script = soup.find('script', text=re.compile(\"window\\['__espnfitt__'\\]\"))\n",
    "    json_text = re.search(r\"^\\s*window\\['__espnfitt__'\\]\\s*=\\s*({.*?})\\s*;\\s*$\",\n",
    "                          script.string, flags=re.DOTALL | re.MULTILINE).group(1)\n",
    "    data = json.loads(json_text)\n",
    "    \n",
    "    #get pbp\n",
    "    pbp = data['page']['content']['gamepackage']['pbp']['playGrps']\n",
    "    pbp = [item for sublist in pbp for item in sublist]\n",
    "    pbp = pd.DataFrame.from_dict(pbp)\n",
    "    \n",
    "    #get shot chart\n",
    "    shot_chart = data['page']['content']['gamepackage']['shtChrt']['plays']\n",
    "    shot_chart = pd.DataFrame.from_dict(shot_chart)\n",
    "    shot_chart = shot_chart[['id','athlete','coordinate','shootingPlay','type']]\n",
    "    \n",
    "    #combine shot chart and pbp\n",
    "    combined_pbp = pd.merge(pbp,shot_chart,on='id',how='outer')\n",
    "    \n",
    "    #clean combined dataframe\n",
    "    combined_pbp['period'] = [re.search('[0-9]',str(x)).group(0) for x in combined_pbp['period']]\n",
    "    combined_pbp['clock'] = [re.search('[0-9]{1,2}([:\\.])[0-9]{1,2}',str(x)).group(0) for x in combined_pbp['clock']]\n",
    "    combined_pbp['player_id'] = [re.search('\\d+',str(x)).group(0) if bool(re.search('\\d+',str(x))) else np.nan for x in combined_pbp['athlete']]\n",
    "    combined_pbp['player'] = [re.sub(\"{'id': '\\d+', 'name': '\",'',str(x)) if bool(re.search(\"{'id': '\\d+', 'name': '\",str(x))) else np.nan for x in combined_pbp['athlete']]\n",
    "    combined_pbp['player'] = [re.sub(\"'}\",'',str(x)) if bool(re.search(\"'}\",str(x))) else np.nan for x in combined_pbp['player']]\n",
    "    combined_pbp['shotType'] = [re.sub(\"{'id': '\\d+', 'txt': '\",'',str(x)) if bool(re.search(\"{'id': '\\d+', 'txt': '\",str(x))) else np.nan for x in combined_pbp['type']]\n",
    "    combined_pbp['shotType'] = [re.sub(\"'}\",'',str(x)) if bool(re.search(\"'}\",str(x))) else np.nan for x in combined_pbp['shotType']]\n",
    "    combined_pbp['shotType'] = [re.sub(\"{'id': '\\d+', 'txt': '\",'',str(x)) if bool(re.search(\"{'id': '\\d+', 'txt': '\",str(x))) else np.nan for x in combined_pbp['type']]\n",
    "    combined_pbp['shotType'] = [re.sub(\"'}\",'',str(x)) if bool(re.search(\"'}\",str(x))) else np.nan for x in combined_pbp['shotType']]\n",
    "    combined_pbp['x_coord'] = [re.findall(\"\\d+\",str(x))[0] if bool(re.search(\"\\d+\",str(x))) else np.nan for x in combined_pbp['coordinate']]\n",
    "    combined_pbp['y_coord'] = [re.findall(\"\\d+\",str(x))[1] if bool(re.search(\"\\d+\",str(x))) else np.nan for x in combined_pbp['coordinate']]\n",
    "    combined_pbp = combined_pbp.drop('athlete', axis=1)\n",
    "    combined_pbp = combined_pbp.drop('type', axis=1)\n",
    "    combined_pbp = combined_pbp.drop('coordinate', axis=1)\n",
    "    \n",
    "    #team info\n",
    "    teams = data['page']['content']['gamepackage']['pbp']['tms']\n",
    "    combined_pbp['homeTeam'] = teams['home']['abbrev']\n",
    "    combined_pbp['awayTeam'] = teams['away']['abbrev']\n",
    "    if 'winner' in teams['home']:\n",
    "        combined_pbp['winner'] = 'home'\n",
    "    elif 'winner' in teams['away']:\n",
    "        combined_pbp['winner'] = 'away'\n",
    "    \n",
    "    #game info\n",
    "    game_info = data['page']['content']['gamepackage']['gmInfo']\n",
    "    combined_pbp['gameID'] = GameID\n",
    "    combined_pbp['dateTime'] = datetime.datetime.strptime(game_info['dtTm'],'%Y-%m-%dT%H:%MZ') - timedelta(hours=7) #put datetime in pacific time\n",
    "    combined_pbp['neutralSite'] = data['page']['content']['gamepackage']['shtChrt']['ntrlSte']\n",
    "    \n",
    "    #return combined_pbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "gid_fails = []\n",
    "#game_ids_test = [401230733]\n",
    "game_ids_test = game_ids\n",
    "for GameID in game_ids_test:\n",
    "    try:\n",
    "        temp = get_game_data(GameID) #for each game id get pbp, shot chart, game info in one table\n",
    "        df = pd.concat([df,temp],ignore_index=True) #append to previous\n",
    "    except:\n",
    "        gid_fails.append(GameID) #if fail, print the gameid\n",
    "        \n",
    "print(gid_fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/raw-data/espn-raw-pbp-'+str(year)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['gameID','dateTime','homeTeam','awayTeam']].drop_duplicates().to_csv(year+\"-scraped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do \n",
    "#go back and get other game info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##archive parse html code not needed with ESPN parsing as of 7/30/22\n",
    "##if True:\n",
    "#def get_game_data(GameID):\n",
    "#    #first get all the game info\n",
    "#    data_type = \"recap\"\n",
    "#    url = espn.get_game_url(data_type, \"wnba\", GameID)\n",
    "#    data = espn.get_url(url)\n",
    "#    temp = data['gamepackageJSON']\n",
    "#    temp = temp['header']   \n",
    "#    #date\n",
    "#    Date = temp['competitions'][0]['date']\n",
    "#    #winning team\n",
    "#    if temp['competitions'][0]['competitors'][0]['winner']: #check if 1st team won\n",
    "#        WinningTeam = temp['competitions'][0]['competitors'][0]['team']['abbreviation']\n",
    "#    else: #otehrwise 2nd team won\n",
    "#        WinningTeam = temp['competitions'][0]['competitors'][1]['team']['abbreviation']\n",
    "#    #regular season or playoffs?\n",
    "#    gametypes = ['none','preseason','regular season','playoffs']\n",
    "#    gametype_int = temp['season']['type']\n",
    "#    GameType = gametypes[gametype_int]\n",
    "#    \n",
    "#    ########################################\n",
    "#    #now get all the play-by-play\n",
    "#    GameID = str(GameID)\n",
    "#    URL = 'https://www.espn.com/wnba/playbyplay?gameId='+GameID\n",
    "#    page = requests.get(URL)\n",
    "#    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#    \n",
    "#    #teams\n",
    "#    teams = [x.text for x in soup.find_all('span', class_='abbrev')]\n",
    "#    AwayTeam = teams[0]\n",
    "#    HomeTeam = teams[1]\n",
    "#    teams = {teams[0]:'away',teams[1]:'home'}\n",
    "#    \n",
    "#    #scrape the shot description table\n",
    "#    times = [x.text for x in soup.find_all('td', class_='time-stamp')]\n",
    "#    plays = [x.text for x in soup.find_all('td', class_='game-details')]\n",
    "#    score = [x.text for x in soup.find_all('td', class_='combined-score')]\n",
    "#    \n",
    "#    #get team names from the logo image urls\n",
    "#    logourl = [x.find('img').get('src') for x in soup.find_all('td', class_='logo')]\n",
    "#    team = [re.match(r\"https.*/wnba/500/(?P<team>[a-z]+)\\.\",x).group('team').upper() for x in logourl]\n",
    "#    homeoraway = [teams[x] for x in team]\n",
    "#    \n",
    "#    #convert to df\n",
    "#    shotdescriptions = pd.DataFrame({'Time': times,\n",
    "#                          'EventDescription': plays,\n",
    "#                          'Score': score,\n",
    "#                          'EventTeam': team,\n",
    "#                          'HomeOrAway':homeoraway})\n",
    "#    shotdescriptions['GameID'] = GameID\n",
    "#    shotdescriptions['Date'] = Date\n",
    "#    shotdescriptions['GameType'] = GameType\n",
    "#    shotdescriptions['WinningTeam'] = WinningTeam\n",
    "#    shotdescriptions['AwayTeam'] = AwayTeam\n",
    "#    shotdescriptions['HomeTeam'] = HomeTeam\n",
    "#    \n",
    "#    \n",
    "#    #get shot chart data for away team\n",
    "#    awayshots = soup.find('ul', class_='shots away-team')\n",
    "#    awayshots = awayshots.find_all('li')\n",
    "#    awayshotchart = []\n",
    "#    for row in awayshots:\n",
    "#        coordtext = row.get('style')\n",
    "#        match = re.match(r\".*left:(?P<xcoord>[0-9\\.]+)%;top:(?P<ycoord>[0-9\\.]+)%;\",coordtext)\n",
    "#        xcoord = match.group('xcoord')\n",
    "#        ycoord = match.group('ycoord')\n",
    "#        ycoord = str(100-float(ycoord))\n",
    "#        row_data = [row.get('class')[0],\n",
    "#                    row.get('data-homeaway'),\n",
    "#                    row.get('data-period'),\n",
    "#                    row.get('data-shooter'),\n",
    "#                    row.get('data-text'),\n",
    "#                    row.get('id'),\n",
    "#                    xcoord,\n",
    "#                    ycoord]\n",
    "#        awayshotchart.append(row_data)\n",
    "#    \n",
    "#    #get shot chart data for home team\n",
    "#    homeshots = soup.find('ul', class_='shots home-team')\n",
    "#    homeshots = homeshots.find_all('li')\n",
    "#    homeshotchart = []\n",
    "#    for row in homeshots:\n",
    "#        coordtext = row.get('style')\n",
    "#        match = re.match(r\".*left:(?P<xcoord>[0-9\\.]+)%;top:(?P<ycoord>[0-9\\.]+)%;\",coordtext)\n",
    "#        xcoord = match.group('xcoord')\n",
    "#        ycoord = match.group('ycoord')\n",
    "#        ycoord = str(100-float(ycoord))\n",
    "#        row_data = [row.get('class')[0],\n",
    "#                    row.get('data-homeaway'),\n",
    "#                    row.get('data-period'),\n",
    "#                    row.get('data-shooter'),\n",
    "#                    row.get('data-text'),\n",
    "#                    row.get('id'),\n",
    "#                    xcoord,\n",
    "#                    ycoord]\n",
    "#        homeshotchart.append(row_data)\n",
    "#    \n",
    "#    awayshotchart = pd.DataFrame(awayshotchart)\n",
    "#    homeshotchart = pd.DataFrame(homeshotchart)\n",
    "#    \n",
    "#    #name columns for shot chart data\n",
    "#    awayshotchart.columns = ['ShotOutcome','EventTeam','Quarter','pid','EventDescription','ShotID','xcoord','ycoord']\n",
    "#    homeshotchart.columns = ['ShotOutcome','EventTeam','Quarter','pid','EventDescription','ShotID','xcoord','ycoord']\n",
    "#    \n",
    "#    #join to shot descriptions\n",
    "#    playindex = 0\n",
    "#    for row in range(len(awayshotchart)):\n",
    "#        not_found = True\n",
    "#        while not_found:\n",
    "#            if shotdescriptions.loc[playindex,'EventDescription']==awayshotchart.loc[row,'EventDescription']:\n",
    "#                if shotdescriptions.loc[playindex,'HomeOrAway']=='away':\n",
    "#                    shotdescriptions.loc[playindex,'ShotOutcome']=awayshotchart.loc[row,'ShotOutcome']\n",
    "#                    shotdescriptions.loc[playindex,'Quarter']=awayshotchart.loc[row,'Quarter']\n",
    "#                    shotdescriptions.loc[playindex,'pid']=awayshotchart.loc[row,'pid']\n",
    "#                    shotdescriptions.loc[playindex,'ShotID']=awayshotchart.loc[row,'ShotID']\n",
    "#                    shotdescriptions.loc[playindex,'xcoord']=awayshotchart.loc[row,'xcoord']\n",
    "#                    shotdescriptions.loc[playindex,'ycoord']=awayshotchart.loc[row,'ycoord']\n",
    "#                    not_found = False\n",
    "#            playindex += 1       \n",
    "#    \n",
    "#    playindex = 0\n",
    "#    for row in range(len(homeshotchart)):\n",
    "#        not_found = True\n",
    "#        while not_found:\n",
    "#            if shotdescriptions.loc[playindex,'EventDescription']==homeshotchart.loc[row,'EventDescription']:\n",
    "#                if shotdescriptions.loc[playindex,'HomeOrAway']=='home':\n",
    "#                    shotdescriptions.loc[playindex,'ShotOutcome']=homeshotchart.loc[row,'ShotOutcome']\n",
    "#                    shotdescriptions.loc[playindex,'Quarter']=homeshotchart.loc[row,'Quarter']\n",
    "#                    shotdescriptions.loc[playindex,'pid']=homeshotchart.loc[row,'pid']\n",
    "#                    shotdescriptions.loc[playindex,'ShotID']=homeshotchart.loc[row,'ShotID']\n",
    "#                    shotdescriptions.loc[playindex,'xcoord']=homeshotchart.loc[row,'xcoord']\n",
    "#                    shotdescriptions.loc[playindex,'ycoord']=homeshotchart.loc[row,'ycoord']\n",
    "#                    not_found = False\n",
    "#            playindex += 1      \n",
    "#    \n",
    "#    #get quarter numbers and scores\n",
    "#    quarter = 1\n",
    "#    shotdescriptions.loc[0,'AwayScore'] = 0\n",
    "#    shotdescriptions.loc[0,'HomeScore'] = 0\n",
    "#    for row in range(0,len(shotdescriptions)):\n",
    "#        if re.match('End of Game',shotdescriptions.loc[row,'EventDescription']) :\n",
    "#            quarter -= 1 #make the end of the game the same as the last quarter\n",
    "#        shotdescriptions.loc[row,'Quarter'] = quarter\n",
    "#        match = re.match((\"([0-9]+) - ([0-9]+)\"),shotdescriptions.loc[row,'Score'])\n",
    "#        shotdescriptions.loc[row,'AwayScore'] = match.group(1)\n",
    "#        shotdescriptions.loc[row,'HomeScore'] = match.group(2)\n",
    "#        if re.match('End',shotdescriptions.loc[row,'EventDescription']) :\n",
    "#            quarter += 1 #if you reach the end of the quarter, go to the next quarter\n",
    "#    \n",
    "#    #return shotdescriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = espn.get_game_url('playbyplay', \"wnba\", 401244185)\n",
    "#data = espn.get_url(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
